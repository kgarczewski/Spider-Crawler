Spider-crawler is a simple crawling and scraping script, used to crawl websites and extracted data from their pages.
Script is looking for every links on the page and divide them into two categories: externals and internals links.

Installation

    Clone this repository to local folder
    Open project with python
    
Use the app

    Run the script with following code: scrapy crawl 'crawler' -o output.<choose output format (csv/json)>
    Enter a website which you want to check in following format: abc.xyz
    
  

